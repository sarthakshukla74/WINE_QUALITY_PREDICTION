# ğŸ· Wine Quality Prediction (Random Forest + Hyperparameter Tuning)

## ğŸ“Œ Project Overview

This project builds a Machine Learning model to predict **wine quality** using physicochemical properties from the WineQT dataset.

The pipeline includes:

* Exploratory Data Analysis (EDA)
* Outlier Detection & Handling (Z-Score + IQR)
* Decision Tree & Random Forest Modeling
* Hyperparameter Optimization using RandomizedSearchCV
* Feature Importance Analysis
* Model Saving using Joblib

---

## ğŸ“‚ Dataset

* Dataset: `WineQT.csv`
* Target variable: `quality`
* Features include:

  * Fixed acidity
  * Volatile acidity
  * Citric acid
  * Residual sugar
  * Chlorides
  * Free sulfur dioxide
  * Total sulfur dioxide
  * Density
  * pH
  * Sulphates
  * Alcohol

---

# ğŸ” 1ï¸âƒ£ Exploratory Data Analysis (EDA)

### âœ” Dataset Inspection

* `.head()`
* `.info()`
* `.describe()`
* Missing value check

### âœ” Correlation Heatmap

Used to understand relationships between variables.

```python
sns.heatmap(data=df.corr(), annot=True)
```

### âœ” Outlier Detection

* Boxplot visualization
* Skewness analysis

### âœ” Distribution Check

* Histogram + KDE
* Skewness printed for each column

---

# âš™ï¸ 2ï¸âƒ£ Outlier Handling Strategy

We used a **conditional approach**:

| Data Distribution | Method Used |        |                          |
| ----------------- | ----------- | ------ | ------------------------ |
| Nearly Normal (   | skew        | â‰¤ 0.3) | Z-score Capping (Â±3 std) |
| Skewed Data       | IQR Method  |        |                          |

### âœ” Z-score Capping

[
Z = \frac{X - \mu}{\sigma}
]

Values beyond Â±3 standard deviations were capped.

### âœ” IQR Method

[
IQR = Q3 - Q1
]
Bounds:

* Lower = Q1 âˆ’ 1.5 Ã— IQR
* Upper = Q3 + 1.5 Ã— IQR

---

# ğŸ¤– 3ï¸âƒ£ Model Building

## ğŸ¯ Problem Type

Converted multi-class wine quality into binary classification:

* 0 â†’ Quality â‰¤ 5
* 1 â†’ Quality > 5

---

## ğŸŒ³ Decision Tree Classifier

```python
DecisionTreeClassifier(class_weight='balanced')
```

Evaluation Metrics:

* Accuracy
* Precision
* Recall
* F1 Score
* Classification Report

---

## ğŸŒ² Random Forest Classifier

Initial model trained with default parameters.

```python
RandomForestClassifier()
```

---

# ğŸš€ 4ï¸âƒ£ Hyperparameter Tuning (RandomizedSearchCV)

Used Randomized Search with 5-fold Cross Validation.

### Parameters Tuned:

* `n_estimators`
* `max_depth`
* `max_features`
* `min_samples_split`
* `min_samples_leaf`
* `bootstrap`

```python
RandomizedSearchCV(
    n_iter=50,
    cv=5,
    n_jobs=-1,
    random_state=42
)
```

### ğŸ¯ Why RandomizedSearch?

* Faster than GridSearch
* Explores large parameter space efficiently
* Better generalization via cross-validation

---

# ğŸ“Š 5ï¸âƒ£ Model Evaluation

Metrics used:

* Accuracy
* Precision (Weighted)
* Recall (Weighted)
* F1 Score
* Classification Report

---

# ğŸ“ˆ 6ï¸âƒ£ Feature Importance

Random Forest provides feature importance scores.

```python
best_rf_model.feature_importances_
```

Top important features driving wine quality were visualized using a bar plot.

---

# ğŸ’¾ 7ï¸âƒ£ Model Saving

The best optimized model was saved using Joblib:

```python
joblib.dump(best_rf_model, 'wine_quality_rf_76acc.pkl')
```

Saved file:

```
wine_quality_rf_76acc.pkl
```

---

# ğŸ§  Key Learnings

* Outlier handling improves model stability
* Class imbalance must be handled (`class_weight='balanced'`)
* Hyperparameter tuning significantly improves performance
* Random Forest generally outperforms single Decision Trees
* Feature importance helps interpret black-box models

---

# ğŸ›  Tech Stack

* Python
* Pandas
* NumPy
* Matplotlib
* Seaborn
* Scikit-learn
* SciPy
* Joblib

---

# ğŸ”® Future Improvements

* Try XGBoost / LightGBM
* Use SMOTE for imbalance handling
* Apply Feature Scaling + PCA
* Deploy model using Streamlit
* Convert to multiclass prediction instead of binary

---

# ğŸ‘¨â€ğŸ’» Author

**Sarthak Shukla**
B.Tech CSDS | Machine Learning Enthusiast

---

---
